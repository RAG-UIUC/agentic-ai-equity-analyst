# -*- coding: utf-8 -*-
"""CompanyFilingFetcher

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o0RLlSHS-4aaHhWsxMWF_95OD_0EE7E3
"""

!pip install chromadb

pip install sec-api

pip install sec-api pandarallel ipywidgets

import requests
import pandas as pd
import chromadb
from chromadb.config import Settings
import openai
import uuid
from openai import OpenAI
from dotenv import load_dotenv
from google.colab import userdata
import os

load_dotenv()

EMBEDDING_MODEL = "text-embedding-3-small"

openai_client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))

def embed_text(text):
    resp = openai_client.embeddings.create(model=EMBEDDING_MODEL, input=text)
    return [e.embedding for e in resp.data]

chroma_client = chromadb.CloudClient(
  api_key='ck-yu7vxc2gHZuML9UYAzzHmvvWbEhgxvhxoskugYWi5kR',
  tenant='39d705f2-76cc-419f-adea-b71614d9aeb4',
  database='AIEquityAnalyst ')
collection = chroma_client.get_collection("company_filings")

from urllib.request import urlopen
import certifi, json
import requests

fmp_key = "7lM2tFak5vHHYCmPs8MezCFnNLN3rXXZ"

year = 2022
ticker = "AAPL"
per = "FY" # Q4, FY are 10-K reports; Q1-3 are 10-Q reports

def get_jsonparsed_data(url):
    response = urlopen(url, cafile=certifi.where())
    data = response.read().decode("utf-8")
    return json.loads(data)

url = f"https://financialmodelingprep.com/stable/financial-reports-xlsx?symbol={ticker}&year={year}&period={per}&apikey={fmp_key}"
xcel = requests.get(url) # 1 api call to fmp

read = pd.read_excel(xcel.content, sheet_name=None)
#display(read)
filenamc = ""

if per == "FY" or per == "Q4":
  filename = f"{ticker}_{year}_10-K_filing"
else:
  filename = f"{ticker}_{year}_{per}_10-Q_filing"

#print(filename)

for k, v in read.items():
  v.to_csv(k, index=None, header=True)
  data = pd.read_csv(k)
  df = pd.DataFrame(data);

  #print(v)

  for row in data.iterrows():
    txt = row[1].to_string()
    embedding = embed_text(txt)[0]
    unique_id = str(uuid.uuid4())
    collection.add(embeddings=[embedding], documents=[f"{filename} : {txt}"], ids=[unique_id])

query = "Apple's revenue in 2022"
qemb = embed_text(query)[0]
res = collection.query(query_embeddings=[qemb], n_results=100, include=["documents", "distances"])
#print(res)

rep = openai_client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {"role": "system", "content": "You are a technical financial analyst."},
    {"role": "user", "content": f"Summarize and analyze the following data:{res['documents'][:][0]}"}])

print(rep.choices[0].message.content)